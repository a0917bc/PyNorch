{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (quant): QuantStub()\n",
       "  (conv1): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=1, stride=1)\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.dequant(x)\n",
    "        return x\n",
    "\n",
    "net = CustomModel()\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/triven/miniconda3/envs/OwnTorch/lib/python3.11/site-packages/torch/ao/quantization/observer.py:221: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (conv1): Conv2d(\n",
       "    1, 1, kernel_size=(1, 1), stride=(1, 1)\n",
       "    (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_qconfig = torch.quantization.qconfig.QConfig(\n",
    "        activation=torch.quantization.observer.HistogramObserver.with_args(dtype=torch.quint8, qscheme=torch.per_tensor_affine, reduce_range=True),\n",
    "        weight=torch.quantization.observer.PerChannelMinMaxObserver.with_args(dtype=torch.qint8, qscheme=torch.per_channel_symmetric, reduce_range=False )\n",
    ")\n",
    "\n",
    "net.qconfig = my_qconfig\n",
    "torch.backends.quantized.engine = \"fbgemm\"\n",
    "torch.quantization.prepare(net, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrate_data = torch.randint(low=0, high=255, size=(1, 4, 16), dtype=torch.uint8).unsqueeze(0)\n",
    "calibrate_data = calibrate_data / 255\n",
    "_ = net(calibrate_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (quant): Quantize(scale=tensor([0.0078]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "  (conv1): QuantizedConv2d(1, 1, kernel_size=(1, 1), stride=(1, 1), scale=0.005468083545565605, zero_point=127)\n",
       "  (dequant): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.quantization.convert(net, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (quant): Quantize(scale=tensor([0.0078]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "  (conv1): QuantizedConv2d(1, 1, kernel_size=(1, 1), stride=(1, 1), scale=0.005468083545565605, zero_point=127)\n",
       "  (dequant): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = []\n",
    "def custom_hook(module, input, output):\n",
    "    info = {\n",
    "        'module': module,\n",
    "        'input': input,\n",
    "        'output': output\n",
    "    }\n",
    "    activations.append(info)\n",
    "\n",
    "for name, module in net.named_modules():\n",
    "    if len(list(module.children())) == 0:\n",
    "        module.register_forward_hook(custom_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel1 = torch.arange(0, 64).view(4, 16).to(torch.uint8).unsqueeze(0)\n",
    "input_data = channel1.unsqueeze(0)\n",
    "input_data = input_data / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = net(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0,  0,  0,  1,  1,  2,  2,  2,  2,  3,  3,  4,  4,  5,  5,  5],\n",
       "          [ 5,  6,  6,  7,  7,  7,  7,  8,  8,  9,  9, 10, 10, 10, 10, 11],\n",
       "          [11, 12, 12, 12, 12, 13, 13, 14, 14, 15, 15, 15, 15, 16, 16, 17],\n",
       "          [17, 17, 17, 18, 18, 19, 19, 20, 20, 20, 20, 21, 21, 22, 22, 22]]]],\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations[1]['input'][0].int_repr()\n",
    "activations[1]['output'].int_repr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(64)\n"
     ]
    }
   ],
   "source": [
    "# https://discuss.pytorch.org/t/the-result-of-quantized-conv2d-is-different-from-the-result-i-calculate/157066/6\n",
    "qx = activations[1]['input'][0].int_repr()\n",
    "wx = net.conv1.weight().int_repr()\n",
    "\n",
    "sinput = activations[1]['input'][0].q_scale()\n",
    "sweight = activations[1]['module'].weight().q_per_channel_scales()[0]\n",
    "soutput = activations[1]['module'].scale\n",
    "zinput = activations[1]['input'][0].q_zero_point()\n",
    "zweight = activations[1]['module'].weight().q_per_channel_zero_points()[0]\n",
    "zoutput = activations[1]['module'].zero_point\n",
    "\n",
    "bias = activations[1]['module'].bias()\n",
    "qbias = torch.round(bias / (sinput * sweight))\n",
    "\n",
    "qoutput = qx * wx + qbias\n",
    "qoutput = torch.round(qoutput * sinput * sweight / soutput + zoutput)\n",
    "qoutput = torch.clamp(qoutput, 0, 127)\n",
    "print((activations[1]['output'].int_repr() == qoutput).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0078393230214715"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sinput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zinput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed-point multiplication result: 46875\n"
     ]
    }
   ],
   "source": [
    "def fixed_point_multiply(value, M0, n):\n",
    "    # Step 1: Convert M0 to a 32-bit fixed-point integer\n",
    "    M0_fixed = int(round((2**31) * M0))\n",
    "    \n",
    "    # Step 2: Perform the multiplication in fixed-point\n",
    "    result_fixed = (value * M0_fixed) >> 31\n",
    "    \n",
    "    # Step 3: Apply the bit shift for 2^(-n)\n",
    "    result_shifted = result_fixed >> n\n",
    "    \n",
    "    return result_shifted\n",
    "\n",
    "# Example values\n",
    "M0 = 0.75  # Example M0 in [0.5, 1)\n",
    "n = 4      # Example n\n",
    "value = 1000000  # Example value to be multiplied\n",
    "\n",
    "# Perform the fixed-point multiplication\n",
    "result = fixed_point_multiply(value, M0, n)\n",
    "\n",
    "print(f\"Fixed-point multiplication result: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "M0_fixed = int(round((2**31) * M0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1610612736"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M0_fixed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OwnTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
